# learningforplanning
                      Folders and Files
                      

     For Data Genration:
Script in photorealistic-blockworld-master folder are used for generate photorealistic data, but you have to install blender before run it.
The link below introduces how to generate photorealistic data in detail.
       https://github.com/sontung/photorealistic-blocksworld

     For Data:
you can find our data here:    https://drive.google.com/drive/folders/1szDToDPCO9bwP1S5Lg-WuMCKfKQzCZkI?usp=sharing

      For DataLoading
We use the data_loader.py script to load our image data.
The data folder (link below) contains the loaded data we used to train the autoencoder and do other tasks. These data are extracted from the visual data.
https://drive.google.com/drive/folders/1yOeUfWFkWcxhbg2iXEQBigcaInrypcbn?usp=sharing

      For model train:

We use the models.py script for creating the autoencoder model and train_us.py script for training. The utils.py and resnet.py should be imported for the model creation and train.
The logs folder (link below) contains the results of validating the autoencoder.
      https://drive.google.com/drive/folders/18cDJFdl9cW_750sAVlw4KYDK058YdCif?usp=sharing
The figure folder (link below) contains the visual result of validating the autoencoder.
      https://drive.google.com/drive/folders/1teW091Pdd1wHjq9FRuDNBEY628qH8Frw?usp=sharing
The pre_models folder (link below) contains some autoencoder model we trained.
https://drive.google.com/drive/folders/1OBJYaKnsVh-m8-7oNCNEkRF6669aHQCq?usp=sharing

      For integrating the work of Ke and Irene:

The calibration.py script works for outputting data that would be used for estimating 3D information (Irene’s part)
coordinates.pickles (first link below) and block5_3.pkl (second link below) are data generated by calibration.py.
https://drive.google.com/file/d/10TcOPcoWyG7H4wJEsNtq1B3Bbus2Woxg/view?usp=sharing
https://drive.google.com/file/d/1VetOrFM0dGM4GQ3nuzkxYYljfGjF72fD/view?usp=sharing

      For 3D estimate:

fp_callibration_auto.ipynb are used to estimate 3D information
results are save in predicted_3D_coords

      For 3D scene graph test:

SGvalidate.py would test the scene graph created by our estimated 3D information.

      For A* search —> to see the performance of our results:

The current_plan_with_heuristics.py uses A* for action planning on scene graph

      For Demo:

The simulator.py would demonstrate our results
The ‘demo’ folder contains some demonstrations of our algorithm.


          
                       How to Run

If you want to check all codes from scratch, you can run them one by one in the order described above. If you just want to test a random scenario, just run the current_plan_with_heuristics.py  directly. But you need to download all the relevant data (data links have been given) first in advance.
